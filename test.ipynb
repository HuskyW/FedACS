{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5063638b8543486ea1ba6264cd7ebdf0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/mnist/MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "770a5ad11ffd47c0a868dfc4b406a289"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcccda3c1e7048c9919c1f5dde0e3b0d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b3214dbc7634c7bb8bf6416e5f1a30e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n",
      "MLP(\n",
      "  (layer_input): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (layer_hidden): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.351771\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 1.294999\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.969062\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.777950\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.545943\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.739621\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.708313\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.565550\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.589831\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.541472\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.685840\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.422444\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.317990\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.587254\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.439984\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.607359\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.453803\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.521237\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.255477\n",
      "\n",
      "Train loss: 0.6565952101178261\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.740575\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.446926\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.369341\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.378050\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.454444\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.251609\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.391250\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.357127\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.306979\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.292711\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.409273\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.337152\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.340289\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.507519\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.490476\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.311061\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.290898\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.391286\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.385824\n",
      "\n",
      "Train loss: 0.39547013737626674\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.467122\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.301972\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.392222\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.374035\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.496869\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.382050\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.228372\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.309908\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.204455\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.340149\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.349881\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.436850\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.219777\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.278909\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.260387\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.316999\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.510351\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.292562\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.262658\n",
      "\n",
      "Train loss: 0.34513840770352877\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.274425\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.362857\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.292826\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.267000\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.245288\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.343829\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.202370\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.298411\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.207561\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.431622\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.181950\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.593336\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.170310\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.307412\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.297097\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.208498\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.417248\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.221979\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.236625\n",
      "\n",
      "Train loss: 0.31414692107834286\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.468529\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.255634\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.363990\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.130022\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.171798\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.283789\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.371388\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.141611\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.317380\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.243999\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.323348\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.232716\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.478556\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.341861\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.385860\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.267040\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.531673\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.259217\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.262104\n",
      "\n",
      "Train loss: 0.2945908291706208\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.218493\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.243468\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.195095\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.249031\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.260787\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.275218\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.233927\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.290208\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.211142\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.292452\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.213958\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.223790\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.288089\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.328651\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.262921\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.168887\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.358659\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.186191\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.198691\n",
      "\n",
      "Train loss: 0.28217339864385915\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.134232\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.270417\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.347809\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.597530\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.165131\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.204577\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.195878\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.219876\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.260072\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.222595\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.327286\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.176664\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.246893\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.476340\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.308587\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.092821\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.332092\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.620248\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.374925\n",
      "\n",
      "Train loss: 0.2717807293613392\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.372324\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.209847\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.312026\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.167742\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.324240\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.155376\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.175163\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.121720\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.146970\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.264751\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.270553\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.278403\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.250492\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.373040\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.172462\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.166358\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.348794\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.290279\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.354431\n",
      "\n",
      "Train loss: 0.2602550897008575\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.428259\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.307991\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.412055\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.297240\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.334966\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.166964\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.481476\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.236919\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.164046\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.335331\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.214961\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.255112\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.237355\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.217105\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.180481\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.247960\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.198177\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.246554\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.125312\n",
      "\n",
      "Train loss: 0.2557433773356397\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.409374\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.285166\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.161994\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.279433\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.239723\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.234803\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.220238\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.309563\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.210092\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.252957\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.145895\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.138676\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.321831\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.214145\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.265654\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.129922\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.089110\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.204789\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.227535\n",
      "\n",
      "Train loss: 0.2488047351746925\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './log/nn_mnist_mlp_10.png'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\PythonProjects\\federated-learning\\main_nn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./log/nn_{}_{}_{}.png'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;31m# testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   2178\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2180\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m   2080\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2081\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2082\u001b[1;33m                     **kwargs)\n\u001b[0m\u001b[0;32m   2083\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2084\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m                     \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[0;32m    532\u001b[0m                                self.figure.dpi, metadata=metadata)\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[1;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m     \u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[1;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m         \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'seek'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './log/nn_mnist_mlp_10.png'"
     ]
    }
   ],
   "source": [
    "%run main_nn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n",
      "CNNMnist(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "Round   1, Average loss 2.266\n",
      "Testing accuracy: 10.76\n",
      "Round   2, Average loss 2.284\n",
      "Testing accuracy: 11.15\n",
      "Round   3, Average loss 2.311\n",
      "Testing accuracy: 10.71\n",
      "Round   4, Average loss 2.255\n",
      "Testing accuracy: 12.72\n",
      "Round   5, Average loss 2.292\n",
      "Testing accuracy: 11.29\n",
      "Round   6, Average loss 2.283\n",
      "Testing accuracy: 13.16\n",
      "Round   7, Average loss 2.305\n",
      "Testing accuracy: 14.79\n",
      "Round   8, Average loss 2.267\n",
      "Testing accuracy: 16.73\n",
      "Round   9, Average loss 2.295\n",
      "Testing accuracy: 14.82\n",
      "Round  10, Average loss 2.301\n",
      "Testing accuracy: 16.52\n",
      "Round  11, Average loss 2.275\n",
      "Testing accuracy: 15.49\n",
      "Round  12, Average loss 2.260\n",
      "Testing accuracy: 13.63\n",
      "Round  13, Average loss 2.271\n",
      "Testing accuracy: 14.25\n",
      "Round  14, Average loss 2.287\n",
      "Testing accuracy: 18.19\n",
      "Round  15, Average loss 2.278\n",
      "Testing accuracy: 18.22\n",
      "Round  16, Average loss 2.263\n",
      "Testing accuracy: 17.48\n",
      "Round  17, Average loss 2.263\n",
      "Testing accuracy: 19.38\n",
      "Round  18, Average loss 2.275\n",
      "Testing accuracy: 19.21\n",
      "Round  19, Average loss 2.260\n",
      "Testing accuracy: 20.83\n",
      "Round  20, Average loss 2.239\n",
      "Testing accuracy: 16.76\n",
      "Round  21, Average loss 2.262\n",
      "Testing accuracy: 15.93\n",
      "Round  22, Average loss 2.228\n",
      "Testing accuracy: 18.98\n",
      "Round  23, Average loss 2.230\n",
      "Testing accuracy: 22.75\n",
      "Round  24, Average loss 2.225\n",
      "Testing accuracy: 23.74\n",
      "Round  25, Average loss 2.227\n",
      "Testing accuracy: 23.54\n",
      "Round  26, Average loss 2.258\n",
      "Testing accuracy: 22.71\n",
      "Round  27, Average loss 2.239\n",
      "Testing accuracy: 24.69\n",
      "Round  28, Average loss 2.248\n",
      "Testing accuracy: 27.68\n",
      "Round  29, Average loss 2.235\n",
      "Testing accuracy: 31.73\n",
      "Round  30, Average loss 2.223\n",
      "Testing accuracy: 30.39\n",
      "Round  31, Average loss 2.204\n",
      "Testing accuracy: 26.19\n",
      "Round  32, Average loss 2.213\n",
      "Testing accuracy: 29.77\n",
      "Round  33, Average loss 2.206\n",
      "Testing accuracy: 22.90\n",
      "Round  34, Average loss 2.217\n",
      "Testing accuracy: 32.06\n",
      "Round  35, Average loss 2.195\n",
      "Testing accuracy: 34.89\n",
      "Round  36, Average loss 2.198\n",
      "Testing accuracy: 40.48\n",
      "Round  37, Average loss 2.188\n",
      "Testing accuracy: 46.10\n",
      "Round  38, Average loss 2.174\n",
      "Testing accuracy: 44.70\n",
      "Round  39, Average loss 2.153\n",
      "Testing accuracy: 45.10\n",
      "Round  40, Average loss 2.178\n",
      "Testing accuracy: 38.35\n",
      "Round  41, Average loss 2.200\n",
      "Testing accuracy: 43.41\n",
      "Round  42, Average loss 2.149\n",
      "Testing accuracy: 42.27\n",
      "Round  43, Average loss 2.174\n",
      "Testing accuracy: 45.24\n",
      "Round  44, Average loss 2.155\n",
      "Testing accuracy: 48.11\n",
      "Round  45, Average loss 2.113\n",
      "Testing accuracy: 47.65\n",
      "Round  46, Average loss 2.165\n",
      "Testing accuracy: 48.93\n",
      "Round  47, Average loss 2.122\n",
      "Testing accuracy: 43.68\n",
      "Round  48, Average loss 2.093\n",
      "Testing accuracy: 44.85\n",
      "Round  49, Average loss 2.127\n",
      "Testing accuracy: 46.57\n",
      "Round  50, Average loss 2.093\n",
      "Testing accuracy: 48.95\n",
      "Round  51, Average loss 2.038\n",
      "Testing accuracy: 42.08\n",
      "Round  52, Average loss 2.100\n",
      "Testing accuracy: 45.46\n",
      "Round  53, Average loss 2.087\n",
      "Testing accuracy: 45.59\n",
      "Round  54, Average loss 2.075\n",
      "Testing accuracy: 54.35\n",
      "Round  55, Average loss 2.050\n",
      "Testing accuracy: 44.89\n",
      "Round  56, Average loss 1.968\n",
      "Testing accuracy: 37.71\n",
      "Round  57, Average loss 2.121\n",
      "Testing accuracy: 49.69\n",
      "Round  58, Average loss 1.993\n",
      "Testing accuracy: 50.27\n",
      "Round  59, Average loss 1.999\n",
      "Testing accuracy: 52.20\n",
      "Round  60, Average loss 1.996\n",
      "Testing accuracy: 51.26\n",
      "Round  61, Average loss 1.971\n",
      "Testing accuracy: 52.29\n",
      "Round  62, Average loss 1.952\n",
      "Testing accuracy: 54.30\n",
      "Round  63, Average loss 1.906\n",
      "Testing accuracy: 51.99\n",
      "Round  64, Average loss 1.986\n",
      "Testing accuracy: 58.60\n",
      "Round  65, Average loss 1.957\n",
      "Testing accuracy: 61.69\n",
      "Round  66, Average loss 1.949\n",
      "Testing accuracy: 55.88\n",
      "Round  67, Average loss 1.789\n",
      "Testing accuracy: 59.17\n",
      "Round  68, Average loss 1.872\n",
      "Testing accuracy: 54.45\n",
      "Round  69, Average loss 1.866\n",
      "Testing accuracy: 60.30\n",
      "Round  70, Average loss 1.774\n",
      "Testing accuracy: 57.66\n",
      "Round  71, Average loss 1.991\n",
      "Testing accuracy: 63.75\n",
      "Round  72, Average loss 1.785\n",
      "Testing accuracy: 66.78\n",
      "Round  73, Average loss 1.732\n",
      "Testing accuracy: 60.13\n",
      "Round  74, Average loss 1.720\n",
      "Testing accuracy: 67.87\n",
      "Round  75, Average loss 1.786\n",
      "Testing accuracy: 65.41\n",
      "Round  76, Average loss 1.791\n",
      "Testing accuracy: 71.53\n",
      "Round  77, Average loss 1.831\n",
      "Testing accuracy: 71.21\n",
      "Round  78, Average loss 1.735\n",
      "Testing accuracy: 74.28\n",
      "Round  79, Average loss 1.679\n",
      "Testing accuracy: 70.10\n",
      "Round  80, Average loss 1.698\n",
      "Testing accuracy: 71.79\n",
      "Round  81, Average loss 1.655\n",
      "Testing accuracy: 69.27\n",
      "Round  82, Average loss 1.717\n",
      "Testing accuracy: 59.52\n",
      "Round  83, Average loss 1.668\n",
      "Testing accuracy: 69.99\n",
      "Round  84, Average loss 1.626\n",
      "Testing accuracy: 73.04\n",
      "Round  85, Average loss 1.524\n",
      "Testing accuracy: 70.97\n",
      "Round  86, Average loss 1.605\n",
      "Testing accuracy: 70.21\n",
      "Round  87, Average loss 1.551\n",
      "Testing accuracy: 69.48\n",
      "Round  88, Average loss 1.568\n",
      "Testing accuracy: 75.12\n",
      "Round  89, Average loss 1.570\n",
      "Testing accuracy: 72.91\n",
      "Round  90, Average loss 1.584\n",
      "Testing accuracy: 79.17\n",
      "Round  91, Average loss 1.473\n",
      "Testing accuracy: 77.51\n",
      "Round  92, Average loss 1.443\n",
      "Testing accuracy: 70.35\n",
      "Round  93, Average loss 1.391\n",
      "Testing accuracy: 69.14\n",
      "Round  94, Average loss 1.412\n",
      "Testing accuracy: 69.68\n",
      "Round  95, Average loss 1.348\n",
      "Testing accuracy: 67.46\n",
      "Round  96, Average loss 1.442\n",
      "Testing accuracy: 73.08\n",
      "Round  97, Average loss 1.452\n",
      "Testing accuracy: 77.39\n",
      "Round  98, Average loss 1.396\n",
      "Testing accuracy: 78.17\n",
      "Round  99, Average loss 1.381\n",
      "Testing accuracy: 75.24\n",
      "Round 100, Average loss 1.387\n",
      "Testing accuracy: 71.89\n",
      "Round 101, Average loss 1.314\n",
      "Testing accuracy: 76.89\n",
      "Round 102, Average loss 1.299\n",
      "Testing accuracy: 78.12\n",
      "Round 103, Average loss 1.334\n",
      "Testing accuracy: 74.34\n",
      "Round 104, Average loss 1.416\n",
      "Testing accuracy: 75.56\n",
      "Round 105, Average loss 1.226\n",
      "Testing accuracy: 77.38\n",
      "Round 106, Average loss 1.176\n",
      "Testing accuracy: 70.28\n",
      "Round 107, Average loss 1.355\n",
      "Testing accuracy: 79.54\n",
      "Round 108, Average loss 1.288\n",
      "Testing accuracy: 78.16\n",
      "Round 109, Average loss 1.111\n",
      "Testing accuracy: 72.96\n",
      "Round 110, Average loss 1.349\n",
      "Testing accuracy: 78.89\n",
      "Round 111, Average loss 1.253\n",
      "Testing accuracy: 78.90\n",
      "Round 112, Average loss 1.208\n",
      "Testing accuracy: 74.09\n",
      "Round 113, Average loss 1.143\n",
      "Testing accuracy: 74.97\n",
      "Round 114, Average loss 1.044\n",
      "Testing accuracy: 75.09\n",
      "Round 115, Average loss 1.149\n",
      "Testing accuracy: 78.97\n",
      "Round 116, Average loss 1.115\n",
      "Testing accuracy: 72.11\n",
      "Round 117, Average loss 1.280\n",
      "Testing accuracy: 78.91\n",
      "Round 118, Average loss 1.089\n",
      "Testing accuracy: 75.42\n",
      "Round 119, Average loss 1.174\n",
      "Testing accuracy: 77.67\n",
      "Round 120, Average loss 1.153\n",
      "Testing accuracy: 76.98\n",
      "Round 121, Average loss 1.137\n",
      "Testing accuracy: 79.48\n",
      "Round 122, Average loss 1.089\n",
      "Testing accuracy: 80.84\n",
      "Round 123, Average loss 1.135\n",
      "Testing accuracy: 77.96\n",
      "Round 124, Average loss 1.172\n",
      "Testing accuracy: 83.32\n",
      "Round 125, Average loss 0.955\n",
      "Testing accuracy: 74.95\n",
      "Round 126, Average loss 1.014\n",
      "Testing accuracy: 77.69\n",
      "Round 127, Average loss 1.051\n",
      "Testing accuracy: 81.86\n",
      "Round 128, Average loss 1.078\n",
      "Testing accuracy: 79.49\n",
      "Round 129, Average loss 1.030\n",
      "Testing accuracy: 81.82\n",
      "Round 130, Average loss 0.986\n",
      "Testing accuracy: 79.65\n",
      "Round 131, Average loss 0.996\n",
      "Testing accuracy: 77.93\n",
      "Round 132, Average loss 1.097\n",
      "Testing accuracy: 82.68\n",
      "Round 133, Average loss 1.003\n",
      "Testing accuracy: 80.12\n",
      "Round 134, Average loss 1.051\n",
      "Testing accuracy: 80.39\n",
      "Round 135, Average loss 1.027\n",
      "Testing accuracy: 75.62\n",
      "Round 136, Average loss 1.104\n",
      "Testing accuracy: 77.23\n",
      "Round 137, Average loss 1.027\n",
      "Testing accuracy: 80.78\n",
      "Round 138, Average loss 1.081\n",
      "Testing accuracy: 84.20\n",
      "Round 139, Average loss 1.002\n",
      "Testing accuracy: 83.20\n",
      "Round 140, Average loss 0.925\n",
      "Testing accuracy: 81.07\n",
      "Round 141, Average loss 0.946\n",
      "Testing accuracy: 82.00\n",
      "Round 142, Average loss 0.968\n",
      "Testing accuracy: 78.00\n",
      "Round 143, Average loss 0.946\n",
      "Testing accuracy: 82.81\n",
      "Round 144, Average loss 1.091\n",
      "Testing accuracy: 84.33\n",
      "Round 145, Average loss 0.972\n",
      "Testing accuracy: 82.53\n",
      "Round 146, Average loss 1.020\n",
      "Testing accuracy: 85.22\n",
      "Round 147, Average loss 0.965\n",
      "Testing accuracy: 82.74\n",
      "Round 148, Average loss 0.912\n",
      "Testing accuracy: 84.24\n",
      "Round 149, Average loss 0.869\n",
      "Testing accuracy: 79.73\n",
      "Round 150, Average loss 0.866\n",
      "Testing accuracy: 82.70\n",
      "Round 151, Average loss 0.833\n",
      "Testing accuracy: 80.72\n",
      "Round 152, Average loss 0.850\n",
      "Testing accuracy: 81.40\n",
      "Round 153, Average loss 0.871\n",
      "Testing accuracy: 82.12\n",
      "Round 154, Average loss 0.934\n",
      "Testing accuracy: 79.83\n",
      "Round 155, Average loss 0.996\n",
      "Testing accuracy: 85.61\n",
      "Round 156, Average loss 0.981\n",
      "Testing accuracy: 82.00\n",
      "Round 157, Average loss 0.908\n",
      "Testing accuracy: 81.97\n",
      "Round 158, Average loss 0.933\n",
      "Testing accuracy: 82.32\n",
      "Round 159, Average loss 0.843\n",
      "Testing accuracy: 84.61\n",
      "Round 160, Average loss 0.696\n",
      "Testing accuracy: 82.51\n",
      "Round 161, Average loss 0.855\n",
      "Testing accuracy: 82.45\n",
      "Round 162, Average loss 0.718\n",
      "Testing accuracy: 80.43\n",
      "Round 163, Average loss 0.925\n",
      "Testing accuracy: 84.11\n",
      "Round 164, Average loss 0.755\n",
      "Testing accuracy: 81.38\n",
      "Round 165, Average loss 0.765\n",
      "Testing accuracy: 82.31\n",
      "Round 166, Average loss 0.902\n",
      "Testing accuracy: 84.91\n",
      "Round 167, Average loss 0.829\n",
      "Testing accuracy: 84.51\n",
      "Round 168, Average loss 0.825\n",
      "Testing accuracy: 84.08\n",
      "Round 169, Average loss 0.823\n",
      "Testing accuracy: 85.81\n",
      "Round 170, Average loss 0.780\n",
      "Testing accuracy: 84.47\n",
      "Round 171, Average loss 0.833\n",
      "Testing accuracy: 85.78\n",
      "Round 172, Average loss 0.920\n",
      "Testing accuracy: 84.91\n",
      "Round 173, Average loss 0.902\n",
      "Testing accuracy: 86.01\n",
      "Round 174, Average loss 0.870\n",
      "Testing accuracy: 85.48\n",
      "Round 175, Average loss 0.775\n",
      "Testing accuracy: 82.97\n",
      "Round 176, Average loss 0.872\n",
      "Testing accuracy: 85.95\n",
      "Round 177, Average loss 0.821\n",
      "Testing accuracy: 86.44\n",
      "Round 178, Average loss 0.789\n",
      "Testing accuracy: 86.11\n",
      "Round 179, Average loss 0.743\n",
      "Testing accuracy: 85.20\n",
      "Round 180, Average loss 0.830\n",
      "Testing accuracy: 85.62\n",
      "Round 181, Average loss 0.739\n",
      "Testing accuracy: 86.30\n",
      "Round 182, Average loss 0.823\n",
      "Testing accuracy: 86.02\n",
      "Round 183, Average loss 0.783\n",
      "Testing accuracy: 83.85\n",
      "Round 184, Average loss 0.826\n",
      "Testing accuracy: 85.34\n",
      "Round 185, Average loss 0.687\n",
      "Testing accuracy: 80.23\n",
      "Round 186, Average loss 0.940\n",
      "Testing accuracy: 85.63\n",
      "Round 187, Average loss 0.735\n",
      "Testing accuracy: 84.95\n",
      "Round 188, Average loss 0.832\n",
      "Testing accuracy: 83.53\n",
      "Round 189, Average loss 0.825\n",
      "Testing accuracy: 86.77\n",
      "Round 190, Average loss 0.732\n",
      "Testing accuracy: 85.88\n",
      "Round 191, Average loss 0.657\n",
      "Testing accuracy: 83.04\n",
      "Round 192, Average loss 0.835\n",
      "Testing accuracy: 86.33\n",
      "Round 193, Average loss 0.716\n",
      "Testing accuracy: 86.79\n",
      "Round 194, Average loss 0.707\n",
      "Testing accuracy: 85.20\n",
      "Round 195, Average loss 0.738\n",
      "Testing accuracy: 84.33\n",
      "Round 196, Average loss 0.649\n",
      "Testing accuracy: 82.87\n",
      "Round 197, Average loss 0.802\n",
      "Testing accuracy: 86.21\n",
      "Round 198, Average loss 0.755\n",
      "Testing accuracy: 86.58\n",
      "Round 199, Average loss 0.670\n",
      "Testing accuracy: 84.82\n",
      "Round 200, Average loss 0.681\n",
      "Testing accuracy: 85.68\n",
      "Round 201, Average loss 0.789\n",
      "Testing accuracy: 86.77\n",
      "Round 202, Average loss 0.687\n",
      "Testing accuracy: 84.43\n",
      "Round 203, Average loss 0.756\n",
      "Testing accuracy: 84.35\n",
      "Round 204, Average loss 0.734\n",
      "Testing accuracy: 86.80\n",
      "Round 205, Average loss 0.726\n",
      "Testing accuracy: 87.09\n",
      "Round 206, Average loss 0.754\n",
      "Testing accuracy: 85.87\n",
      "Round 207, Average loss 0.702\n",
      "Testing accuracy: 86.93\n",
      "Round 208, Average loss 0.626\n",
      "Testing accuracy: 86.29\n",
      "Round 209, Average loss 0.724\n",
      "Testing accuracy: 86.65\n",
      "Round 210, Average loss 0.673\n",
      "Testing accuracy: 86.17\n",
      "Round 211, Average loss 0.681\n",
      "Testing accuracy: 86.71\n",
      "Round 212, Average loss 0.563\n",
      "Testing accuracy: 85.26\n",
      "Round 213, Average loss 0.782\n",
      "Testing accuracy: 86.51\n",
      "Round 214, Average loss 0.783\n",
      "Testing accuracy: 87.06\n",
      "Round 215, Average loss 0.705\n",
      "Testing accuracy: 84.41\n",
      "Round 216, Average loss 0.759\n",
      "Testing accuracy: 87.17\n",
      "Round 217, Average loss 0.771\n",
      "Testing accuracy: 87.05\n",
      "Round 218, Average loss 0.664\n",
      "Testing accuracy: 85.69\n",
      "Round 219, Average loss 0.677\n",
      "Testing accuracy: 86.45\n",
      "Round 220, Average loss 0.722\n",
      "Testing accuracy: 86.98\n",
      "Round 221, Average loss 0.683\n",
      "Testing accuracy: 87.45\n",
      "Round 222, Average loss 0.630\n",
      "Testing accuracy: 84.13\n",
      "Round 223, Average loss 0.581\n",
      "Testing accuracy: 85.91\n",
      "Round 224, Average loss 0.711\n",
      "Testing accuracy: 84.13\n",
      "Round 225, Average loss 0.732\n",
      "Testing accuracy: 86.07\n",
      "Round 226, Average loss 0.606\n",
      "Testing accuracy: 85.37\n",
      "Round 227, Average loss 0.649\n",
      "Testing accuracy: 86.64\n",
      "Round 228, Average loss 0.721\n",
      "Testing accuracy: 87.08\n",
      "Round 229, Average loss 0.644\n",
      "Testing accuracy: 87.58\n",
      "Round 230, Average loss 0.691\n",
      "Testing accuracy: 85.65\n",
      "Round 231, Average loss 0.764\n",
      "Testing accuracy: 87.20\n",
      "Round 232, Average loss 0.667\n",
      "Testing accuracy: 86.96\n",
      "Round 233, Average loss 0.729\n",
      "Testing accuracy: 87.72\n",
      "Round 234, Average loss 0.665\n",
      "Testing accuracy: 86.48\n",
      "Round 235, Average loss 0.659\n",
      "Testing accuracy: 85.28\n",
      "Round 236, Average loss 0.704\n",
      "Testing accuracy: 88.20\n",
      "Round 237, Average loss 0.626\n",
      "Testing accuracy: 86.33\n",
      "Round 238, Average loss 0.669\n",
      "Testing accuracy: 86.96\n",
      "Round 239, Average loss 0.721\n",
      "Testing accuracy: 86.63\n",
      "Round 240, Average loss 0.624\n",
      "Testing accuracy: 87.08\n",
      "Round 241, Average loss 0.541\n",
      "Testing accuracy: 85.93\n",
      "Round 242, Average loss 0.604\n",
      "Testing accuracy: 85.11\n",
      "Round 243, Average loss 0.592\n",
      "Testing accuracy: 83.88\n",
      "Round 244, Average loss 0.651\n",
      "Testing accuracy: 85.75\n",
      "Round 245, Average loss 0.630\n",
      "Testing accuracy: 86.12\n",
      "Round 246, Average loss 0.652\n",
      "Testing accuracy: 87.91\n",
      "Round 247, Average loss 0.631\n",
      "Testing accuracy: 87.16\n",
      "Round 248, Average loss 0.697\n",
      "Testing accuracy: 87.14\n",
      "Round 249, Average loss 0.610\n",
      "Testing accuracy: 87.91\n",
      "Round 250, Average loss 0.590\n",
      "Testing accuracy: 87.91\n",
      "Round 251, Average loss 0.603\n",
      "Testing accuracy: 87.58\n",
      "Round 252, Average loss 0.700\n",
      "Testing accuracy: 88.29\n",
      "Round 253, Average loss 0.652\n",
      "Testing accuracy: 88.32\n",
      "Round 254, Average loss 0.560\n",
      "Testing accuracy: 87.01\n",
      "Round 255, Average loss 0.571\n",
      "Testing accuracy: 85.50\n",
      "Round 256, Average loss 0.652\n",
      "Testing accuracy: 87.84\n",
      "Round 257, Average loss 0.615\n",
      "Testing accuracy: 87.10\n",
      "Round 258, Average loss 0.581\n",
      "Testing accuracy: 88.39\n",
      "Round 259, Average loss 0.539\n",
      "Testing accuracy: 85.38\n",
      "Round 260, Average loss 0.745\n",
      "Testing accuracy: 87.91\n",
      "Round 261, Average loss 0.636\n",
      "Testing accuracy: 88.92\n",
      "Round 262, Average loss 0.556\n",
      "Testing accuracy: 88.48\n",
      "Round 263, Average loss 0.621\n",
      "Testing accuracy: 88.67\n",
      "Round 264, Average loss 0.659\n",
      "Testing accuracy: 88.31\n",
      "Round 265, Average loss 0.660\n",
      "Testing accuracy: 88.09\n",
      "Round 266, Average loss 0.655\n",
      "Testing accuracy: 85.19\n",
      "Round 267, Average loss 0.686\n",
      "Testing accuracy: 85.99\n",
      "Round 268, Average loss 0.699\n",
      "Testing accuracy: 88.94\n",
      "Round 269, Average loss 0.611\n",
      "Testing accuracy: 88.10\n",
      "Round 270, Average loss 0.500\n",
      "Testing accuracy: 86.56\n",
      "Round 271, Average loss 0.660\n",
      "Testing accuracy: 88.84\n",
      "Round 272, Average loss 0.663\n",
      "Testing accuracy: 88.93\n",
      "Round 273, Average loss 0.595\n",
      "Testing accuracy: 88.92\n",
      "Round 274, Average loss 0.622\n",
      "Testing accuracy: 88.78\n",
      "Round 275, Average loss 0.656\n",
      "Testing accuracy: 87.30\n",
      "Round 276, Average loss 0.603\n",
      "Testing accuracy: 87.96\n",
      "Round 277, Average loss 0.696\n",
      "Testing accuracy: 89.04\n",
      "Round 278, Average loss 0.559\n",
      "Testing accuracy: 87.96\n",
      "Round 279, Average loss 0.564\n",
      "Testing accuracy: 86.76\n",
      "Round 280, Average loss 0.647\n",
      "Testing accuracy: 88.87\n",
      "Round 281, Average loss 0.574\n",
      "Testing accuracy: 88.68\n",
      "Round 282, Average loss 0.578\n",
      "Testing accuracy: 89.11\n",
      "Round 283, Average loss 0.544\n",
      "Testing accuracy: 88.89\n",
      "Round 284, Average loss 0.557\n",
      "Testing accuracy: 88.67\n",
      "Round 285, Average loss 0.576\n",
      "Testing accuracy: 88.76\n",
      "Round 286, Average loss 0.529\n",
      "Testing accuracy: 87.92\n",
      "Round 287, Average loss 0.556\n",
      "Testing accuracy: 87.92\n",
      "Round 288, Average loss 0.643\n",
      "Testing accuracy: 88.90\n",
      "Round 289, Average loss 0.673\n",
      "Testing accuracy: 89.54\n",
      "Round 290, Average loss 0.575\n",
      "Testing accuracy: 88.21\n",
      "Round 291, Average loss 0.610\n",
      "Testing accuracy: 88.75\n",
      "Round 292, Average loss 0.570\n",
      "Testing accuracy: 89.01\n",
      "Round 293, Average loss 0.590\n",
      "Testing accuracy: 87.44\n",
      "Round 294, Average loss 0.633\n",
      "Testing accuracy: 88.41\n",
      "Round 295, Average loss 0.662\n",
      "Testing accuracy: 90.01\n",
      "Round 296, Average loss 0.611\n",
      "Testing accuracy: 89.25\n",
      "Round 297, Average loss 0.540\n",
      "Testing accuracy: 89.43\n",
      "Round 298, Average loss 0.577\n",
      "Testing accuracy: 88.84\n",
      "Round 299, Average loss 0.585\n",
      "Testing accuracy: 87.42\n",
      "Round 300, Average loss 0.496\n",
      "Testing accuracy: 88.46\n",
      "Training accuracy: 87.85\n",
      "Testing accuracy: 88.46\n"
     ]
    }
   ],
   "source": [
    "%run main_fed.py --local_ep 1 --frac 0.1 --gpu -1 --epoch 300 --model cnn --num_channels 1 --testing 1 --local_bs 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}